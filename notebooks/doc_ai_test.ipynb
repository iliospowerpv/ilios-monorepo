{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from src.preprocessing.doc_ai.processor import DocAIProcessor\n",
    "import os\n",
    "from google.cloud import documentai\n",
    "from itertools import chain\n",
    "\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = 'prj-ilios-ai.json'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "416ff99bb464bd0a",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple processor "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed1b87938be335fc"
  },
  {
   "cell_type": "code",
   "source": [
    "processor = DocAIProcessor(location=\"us\",\n",
    "                           project_id=\"602280418311\",\n",
    "                           processor_id=\"e977fdd46ee23308\")\n",
    "doc_sequence = processor.process_document(\n",
    "    file_path=\"/Users/odeine/PycharmProjects/ilios-DocAI/data/documents/Site Lease - Novel - Bartel (ES).pdf\")\n",
    "\n",
    "print(f\"Extracted text: \\n\\n {doc_sequence.get_paragraphs()[1]}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6396bc992da61b23",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "all_paragraphs = doc_sequence.get_paragraphs()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9e9f3594899283f",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "len(doc_sequence.get_all_text())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3df1df08da8a6fb8",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "all_paragraphs[2]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5f37c02b2472e2a",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Table processor "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a6d907a2984d428"
  },
  {
   "cell_type": "code",
   "source": [
    "table_processor = DocAIProcessor(\n",
    "    location=\"us\",\n",
    "    project_id=\"602280418311\",\n",
    "    processor_id=\"d89e8046e872374\",\n",
    "    processor_version_id=\"pretrained-form-parser-v2.1-2023-06-26\")\n",
    "doc_sequence_table = table_processor.process_document(\n",
    "    file_path=\"data/Site Lease - Novel - Bartel.pdf\")\n",
    "\n",
    "print(f\"Extracted text: \\n\\n {doc_sequence_table.get_paragraphs()[1]}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cffad6a83c749159",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def concat_strings(strings, string_limit=700, paragraph_limit=200):\n",
    "    # Initialize an empty list to hold the concatenated strings\n",
    "    concatenated = []\n",
    "    # Initialize an empty string to start concatenation\n",
    "    current_string = \"\"\n",
    "\n",
    "    for s in strings:\n",
    "        # Check if the current string is less than 100 characters\n",
    "        # and if adding it would keep the total under 500 characters\n",
    "        if len(s) < paragraph_limit and len(current_string) + len(s) <= string_limit:\n",
    "            # Add the string to the current concatenation\n",
    "            current_string += s\n",
    "        else:\n",
    "            # If the current string is full or the next string is too long,\n",
    "            # move to the next string and reset the current_string\n",
    "            if current_string:  # Avoid adding empty strings\n",
    "                concatenated.append(current_string)\n",
    "            current_string = s  # Start a new concatenation with the current string\n",
    "\n",
    "    # Add the last concatenated string if it's not empty\n",
    "    if current_string:\n",
    "        concatenated.append(current_string)\n",
    "\n",
    "    return concatenated"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a0dc61bda15d6c3",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def layout_to_text(layout: documentai.Document.Page.Layout, text: str) -> str:\n",
    "    return \"\".join(\n",
    "        text[int(segment.start_index) : int(segment.end_index)]\n",
    "        for segment in layout.text_anchor.text_segments\n",
    "    )\n",
    "\n",
    "def parse_table_to_lines(table: documentai.Document.Page.Table, text: str) -> str:\n",
    "    lines = [\"\\nTABLE:\"]\n",
    "    # Extract column names from the header row\n",
    "    column_names = [layout_to_text(cell.layout, text).strip().replace(':', '').replace(\"\\n\", '') for cell in list(table.header_rows)[0].cells]\n",
    "    for row in list(table.body_rows):\n",
    "        line = []\n",
    "        for cell, column_name in zip(row.cells, column_names):\n",
    "            cell_text = layout_to_text(cell.layout, text).replace(\"\\n\", '')\n",
    "            # Include the column name along with the cell text\n",
    "            line.append(f\"{column_name} {cell_text.strip()}\")\n",
    "        lines.append(\": \".join(line))\n",
    "    return \"\\n\".join(lines) + \"\\n\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ec8c2f7a8ab6171",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "text = doc_sequence_table.documents[0].text\n",
    "for table in doc_sequence_table.documents[0].pages[0].tables:\n",
    "    print(parse_table_to_lines(table, text))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee96c118cafa4a2a",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_all_text(documents) -> str:\n",
    "    \"\"\"Returns the text of all the documents\"\"\"\n",
    "    all_text = \"\\n\".join([doc.text for doc in documents])\n",
    "    parsed_tables = [[[parse_table_to_lines(table, document.text) for table in\n",
    "                       page.tables] for page in document.pages] for document in\n",
    "                     documents]\n",
    "    all_text += \"\\n\".join(list(chain.from_iterable(list(chain.from_iterable(parsed_tables)))))\n",
    "\n",
    "    return all_text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a4a7ab87c9d4629",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "get_all_text(doc_sequence_table.documents)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ea6cc3148d44e00",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "97960bdd2e8b6b31",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
